{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47979c7-3e89-48f5-be3d-0879d6b35482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb975f99-62f6-4b7f-9068-c1358a82ca45",
   "metadata": {},
   "source": [
    "### To be Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f079b5af-e6ad-4663-8f86-9e4644f31a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"D:\\\\Dataset 2\\\\\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104497fb-ea45-4217-a4cb-4ae640ddd7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de51d7-0abc-4844-95e2-d4081463aade",
   "metadata": {},
   "source": [
    "### To be Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7feff3-a13d-43ac-91b0-cdfeca59fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for directory_path in glob.glob(\"D:/Dataset 2/train/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path,\"*.jpg\")):\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcca706-9daa-4c5f-8992-91a07b9508b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels_encoded = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e1254-6f6e-46b7-8124-1e62197c23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels_encoded, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c3010-124b-4082-b8b7-91d976a6da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X-Train\",x_train.shape)\n",
    "print(\"Y-Train\",y_train.shape)\n",
    "print(\"X-Test\",x_test.shape)\n",
    "print(\"Y-Test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813ffaa-e346-4f48-843d-54ba6875e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 to 1\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c33861-79f7-4855-b993-2a5100cf0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode y values for neural network\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd3d9b-ef96-42b8-a2f5-aaa8ac778943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model without classifier layers\n",
    "EfficientNet_model = EfficientNetB3(weights=\"imagenet\", include_top=False, input_shape = (SIZE,SIZE,3))\n",
    "EfficientNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b50717-f5dc-4f2d-9277-4795a40f89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in EfficientNet_model.layers:\n",
    "    layer.trainable = False\n",
    "EfficientNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e63de-ab0d-432e-a543-326be15d5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = EfficientNet_model.predict(x_train)\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1616e344-a627-4f4d-8138-3384878e7fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_RF = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ee3cf-8d82-4da0-a77c-964dcf1b711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators=128, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfefc4-5e42-4645-8fcb-76b2d790f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model.fit(X_for_RF, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3efe3ae-d1a9-4664-8d94-bdfd3f16e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = EfficientNet_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8770c-857e-4a21-97fb-f6c0702795de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = X_test_features.reshape(X_test_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb6a77-9cfb-4d3b-a1f7-aeb04c2cf13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_RF = RF_model.predict(X_test_features)\n",
    "#prediction_RF = le.inverse_transform(prediction_RF)\n",
    "display(prediction_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4959b0-f0b9-4f75-898c-cc0f66189c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(y_test, prediction_RF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc19d9-6154-4d1b-8f0f-c7895b271daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, prediction_RF)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83ff29-ec1c-43df-a8d7-ca3202ac21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(0, x_test.shape[0])\n",
    "img = x_test[n]\n",
    "#display(img)\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0)\n",
    "input_img_features = EfficientNet_model.predict(input_img)\n",
    "input_img_features = input_img_features.reshape(input_img_features.shape[0], -1)\n",
    "prediction_RF = RF_model.predict(input_img_features)[0]\n",
    "prediction_RF = le.inverse_transform([prediction_RF])\n",
    "print(\"The prediction for the image is \\t {}\".format(prediction_RF[0].title()))\n",
    "print(\"The actual label for the image is \\t {}\".format(le.inverse_transform([labels_encoded[n]])[0].title()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
