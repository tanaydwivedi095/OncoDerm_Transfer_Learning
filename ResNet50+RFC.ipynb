{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc6453f-2e65-4dd8-b087-6cfc80046c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72000c78-78f1-4720-9fc3-417b441fbed4",
   "metadata": {},
   "source": [
    "### To be Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e038014-7fe1-4e89-a41c-e0c15e1002d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"D:\\\\malignant vs benign\\\\\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6511e2-b4bb-4f07-b47e-32b5ddfb9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7987a21b-fde2-4515-98bd-6402bf982aa1",
   "metadata": {},
   "source": [
    "### To be Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae87d9a-b4ed-45ef-87fc-d9723853d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for directory_path in glob.glob(\"D:/malignant vs benign/train/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path,\"*.jpg\")):\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9995d-901d-42f7-a96f-fcfde5ad6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels_encoded = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76850b4a-4126-491c-a8d0-fe7795064faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels_encoded, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e2fe4-763d-4339-b974-917977b54f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X-Train\",x_train.shape)\n",
    "print(\"Y-Train\",y_train.shape)\n",
    "print(\"X-Test\",x_test.shape)\n",
    "print(\"Y-Test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e165d-733e-4d55-89e6-e0995060d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 to 1\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d889a9-fa17-4db3-9a40-59d4a58bae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode y values for neural network\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa4a3a6-9327-4ffc-89db-b8e47333c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model without classifier layers\n",
    "ResNet_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape = (SIZE,SIZE,3))\n",
    "ResNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02f437-37e4-4264-9ea2-05979e5f748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in ResNet_model.layers:\n",
    "    layer.trainable = False\n",
    "ResNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a9e65-9131-48e8-b60a-c51541fe39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = ResNet_model.predict(x_train)\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14492b04-f878-4a31-a669-d66b116e191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_RF = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eebbbb6-e47c-43ff-af83-0fdb25a09110",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators=128, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696b9a0-5fe3-4482-9c84-1b6871f2894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model.fit(X_for_RF, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a06d7-9efc-4c34-9e92-4a206514c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = ResNet_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9b1db-42ee-493a-ab8b-02f0886dcb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = X_test_features.reshape(X_test_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d5875-0b96-480f-8e14-4aa60d3884d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_RF = RF_model.predict(X_test_features)\n",
    "#prediction_RF = le.inverse_transform(prediction_RF)\n",
    "display(prediction_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322c080-181e-46ea-98f2-728d8c3c212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(y_test, prediction_RF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eeceb3-1f42-43d3-aaff-ef5a44f644a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, prediction_RF)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2beddea-94f3-43a3-81b9-83305fdd4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(0, x_test.shape[0])\n",
    "img = x_test[n]\n",
    "#display(img)\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0)\n",
    "input_img_features = ResNet_model.predict(input_img)\n",
    "input_img_features = input_img_features.reshape(input_img_features.shape[0], -1)\n",
    "prediction_RF = RF_model.predict(input_img_features)[0]\n",
    "prediction_RF = le.inverse_transform([prediction_RF])\n",
    "print(\"The prediction for the image is \\t {}\".format(prediction_RF[0].title()))\n",
    "print(\"The actual label for the image is \\t {}\".format(le.inverse_transform([labels_encoded[n]])[0].title()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
