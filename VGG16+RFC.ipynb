{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81339d3-ba8e-48ad-beaa-78e5eca76ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
    "import seaborn as sns\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97f36b-8eb7-427a-a700-33ef094cf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"D:\\\\malignant vs benign\\\\\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3406e4-481f-4818-bbaf-36907a6ec298",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1915de64-3b85-4deb-81b9-907571b264e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for directory_path in glob.glob(\"D:/malignant vs benign/train/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path,\"*.jpg\")):\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ae805-3585-48fa-81dd-857b49e01f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels_encoded = le.transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30f4bc-9b39-4527-ba39-e4ebcf21fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels_encoded, train_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be5d98-9a3a-4289-a588-01378a1a51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X-Train\",x_train.shape)\n",
    "print(\"Y-Train\",y_train.shape)\n",
    "print(\"X-Test\",x_test.shape)\n",
    "print(\"Y-Test\",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eedab6-86ca-4b25-b294-755a661f8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 to 1\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d431fe5-6d6d-477a-a7be-165245fc8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode y values for neural network\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14779fc8-e00a-4726-8340-a3e1446c4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model without classifier layers\n",
    "VGG_model = VGG16(weights=\"imagenet\", include_top=False, input_shape = (SIZE,SIZE,3))\n",
    "VGG_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a77ea-b51a-4a66-aec6-8073db325373",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in VGG_model.layers:\n",
    "    layer.trainable = False\n",
    "VGG_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e4328-a3ad-454f-b9a5-0bdce3942ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = VGG_model.predict(x_train)\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d630077-b57c-46cd-b9b9-e7e94b5f7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_RF = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c93c3-3440-4650-ad25-d4ce30f9f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators=128, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939b66a-f6a7-40fd-93e5-a3e60d8df76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model.fit(X_for_RF, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad8059-6f47-4273-94b4-08bcd067ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = VGG_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d11367-c298-4089-b722-6dab15087d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = X_test_features.reshape(X_test_features.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b20510-dd05-496e-abdc-72a7f699c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_RF = RF_model.predict(X_test_features)\n",
    "#prediction_RF = le.inverse_transform(prediction_RF)\n",
    "display(prediction_RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e34cd-7f60-416c-a643-11c26f1c6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(y_test, prediction_RF)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd4365-0fe0-4226-929d-c5fc0e33d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, prediction_RF)\n",
    "sns.heatmap(cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9dd9d-4374-4e90-ae4f-c2f658ecffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(0, x_test.shape[0])\n",
    "img = x_test[n]\n",
    "#display(img)\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0)\n",
    "input_img_features = VGG_model.predict(input_img)\n",
    "input_img_features = input_img_features.reshape(input_img_features.shape[0], -1)\n",
    "prediction_RF = RF_model.predict(input_img_features)[0]\n",
    "prediction_RF = le.inverse_transform([prediction_RF])\n",
    "print(\"The prediction for the image is \\t {}\".format(prediction_RF[0].title()))\n",
    "print(\"The actual label for the image is \\t {}\".format(le.inverse_transform([labels_encoded[n]])[0].title()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
