{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be43f9-e11a-4a93-9345-495295bd1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41991eb1-6480-46a8-a5eb-ea57242f21de",
   "metadata": {},
   "source": [
    "### To be Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd50d57d-269b-4d89-b9b8-990034ac38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"D:\\\\Dataset 2\\\\train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be90a0-2120-4461-a96f-dc062e1703be",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358015c6-8af8-4116-9e96-0096803ff946",
   "metadata": {},
   "source": [
    "### To be Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47b1a9-dfbf-4f62-81b5-02e8eda1faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for directory_path in glob.glob(\"D:\\\\Dataset 2\\\\train/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path,\"*.jpg\")):\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cbcc25-cc2f-43b4-ac16-5942f992debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "labels_encoded = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e1bdb-bd49-4c3d-abba-092e4134f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels_encoded, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf526b-02a2-49ae-b1fd-fa4dfb1bf2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X-Train\",x_train.shape)\n",
    "print(\"Y-Train\",y_train.shape)\n",
    "print(\"X-Test\",x_test.shape)\n",
    "print(\"Y-Test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d375f-7419-408b-b789-7ea5fd1af3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 to 1\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f43bdb-a194-4911-9245-66469b138f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode y values for neural network\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fab0c-d695-4600-b4ac-dc93a1f91066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model without classifier layers\n",
    "DenseNet_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape = (SIZE,SIZE,3))\n",
    "DenseNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b647c7-daca-4bcb-86d5-a0e72cd5efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in DenseNet_model.layers:\n",
    "    layer.trainable = False\n",
    "DenseNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8399af-b0f6-4cf6-869f-3fa25e83f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = DenseNet_model.predict(x_train)\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ac158-5345-4cd2-a06f-6f71f83b3bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_RF = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ab61e-8512-4947-b46d-37bf31ffa732",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators=128, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724f80f-7b77-4061-aa73-ac5ef7b6dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model.fit(X_for_RF, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6dc96-0646-4806-b8e9-62386c01f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_featres = DenseNet_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f7266-a9f9-49d9-a9e1-3616caef0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = X_test_features.reshape(X_test_features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc295997-0ca6-4265-b9c9-3254f030cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_RF = RF_model.predict(X_test_features)\n",
    "#prediction_RF = le.inverse_transform(prediction_RF)\n",
    "display(prediction_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a181a-91ed-4a62-8f9c-911782a46e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(y_test, prediction_RF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14bc6b0-088d-4c89-8da4-9ce4422fb809",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, prediction_RF)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f5d8e-eb76-4a82-b1ce-c82f057e56eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(0, x_test.shape[0])\n",
    "img = x_test[n]\n",
    "#display(img)\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0)\n",
    "input_img_features = DenseNet_model.predict(input_img)\n",
    "input_img_features = input_img_features.reshape(input_img_features.shape[0], -1)\n",
    "prediction_RF = RF_model.predict(input_img_features)[0]\n",
    "prediction_RF = le.inverse_transform([prediction_RF])\n",
    "print(\"The prediction for the image is \\t {}\".format(prediction_RF[0].title()))\n",
    "print(\"The actual label for the image is \\t {}\".format(le.inverse_transform([labels_encoded[n]])[0].title()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
